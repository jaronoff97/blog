---
layout: post
title: DS 4100 Week 5 Review
date: 2017-02-12
excerpt: "Data Collection, Integration, and Analysis"
tags: [DS, R, review]
comments: true
hidden: false
project: DS4100
categories:
- DS 4100
---

### DS 4100 Weekly Review

This week I had to write a scraper for class. This was a fun assignment that I got to do in Python. I had a couple of ideas for this assignment, but I was able to decide upon scraping reddit. Reddit has an api, however, this assignment specified that we scrape HTML. I'm really interested in eventually doing sentiment analysis; how does what someone says affect the amount of points they get?

This was a fun project because I got to build a lot of functionality from nothing. I started with the basics: get the page in Python. Once I had the page in Python, I went through the basics. First, I found the different links to the comments pages. I did this by using chrome to find a common trait shared between the comments links. Often times it was a class shared by the text. Once I had the class I would make a method that got all the instances of this property. I then chained each of these properties with methods like so: get the pages > get the comment blocks > get the [user, comment, points]. I would then run this through another method which would go through x amount of pages. This amount of pages would vary based on the amount of data that I wanted. 

To begin these tests, I started with one page. After fixing all the issues from that, I moved on to ten pages. After ten, I expanded it to 100. Once that was done, I had a relatively large data set ~17832 rows. This sort of scraping proved effective. I was worried that I was missing a lot of data, so I went to the actual link to do a sanity check. I found that my scraper was getting everything correct. I really enjoyed this project, and I'm excited to expand on it in the next assignment. 