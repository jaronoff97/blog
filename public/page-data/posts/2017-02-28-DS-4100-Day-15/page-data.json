{"componentChunkName":"component---src-templates-post-template-js","path":"/posts/2017-02-28-DS-4100-Day-15/","webpackCompilationHash":"","result":{"data":{"markdownRemark":{"id":"5298bad4-385d-564d-9a09-cfe5ae19e855","html":"<h3 id=\"ds-4100-data-collection-integration-and-analysis\"><a href=\"#ds-4100-data-collection-integration-and-analysis\" aria-label=\"ds 4100 data collection integration and analysis permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>DS 4100 Data Collection, Integration, and Analysis</h3>\n<p>Today we’re continuing our lesson on statistics. </p>\n<h2 id=\"statistical-inference\"><a href=\"#statistical-inference\" aria-label=\"statistical inference permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Statistical Inference</h2>\n<p>Statistical inference combines the methods of descriptive statistics with the theory of probability to infer characteristics of a large population from small sample.\nThe sample must be selected randomly and must be “large enough” to be statistically significant.</p>\n<h2 id=\"statistical-significance\"><a href=\"#statistical-significance\" aria-label=\"statistical significance permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Statistical Significance</h2>\n<p>Statistical significance means that the characteristics of the sample are likely not due to chance or random error.\nSignificance is expressed by a probability.\nIn most sciences, a confidence level of 95% is generally accepted as statistically significant, i.e., we accept a 5% probability of being wrong about our conclusion.</p>\n<h2 id=\"population-vs-sample\"><a href=\"#population-vs-sample\" aria-label=\"population vs sample permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Population vs. Sample</h2>\n<p>A sample is a small set of randomly selected representatives from a larger population.\nWhen it is impossible (or very difficult) to measure a population, then select a sample.</p>\n<h2 id=\"standard-error\"><a href=\"#standard-error\" aria-label=\"standard error permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Standard Error</h2>\n<p>The standard error of a sample is a measure of the sampling error and can be used to estimate the standard deviation of a population:</p>\n<p>SE = deviation / sqrt(n-1)</p>\n<p>where n is the sample size, i.e., the number of representative elements.</p>\n<h2 id=\"random-sample\"><a href=\"#random-sample\" aria-label=\"random sample permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Random Sample</h2>\n<p>Samples must be drawn randomly which means that each element of the population has the same probability of being included in the sample.\nRandom samples are often drawn through random events, such as assigning numeric identifiers to each element and selecting a set of random numbers through a computer or a random number table.</p>\n<h2 id=\"concept-of-correlation\"><a href=\"#concept-of-correlation\" aria-label=\"concept of correlation permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Concept of Correlation</h2>\n<p>A correlation is a relationship between two variables in which one variable changes in a quantifiable way with another.</p>\n<p>For example, there are correlations between:</p>\n<ul>\n<li>Weight and cholesterol level</li>\n<li>Task completion time and task complexity</li>\n<li>Salary and years of education</li>\n</ul>\n<p>Consider the following:</p>\n<div class=\"gatsby-highlight\" data-language=\"plaintext\"><pre class=\"language-plaintext\"><code class=\"language-plaintext\">In the late 1940s, before there was a polio vaccine, public health experts in America noted that polio cases increased in step with the consumption of ice cream and soft drinks. Eliminating such treats was even recommended as part of an anti-polio diet. It turned out that polio outbreaks were most common in the hot months of summer, when people naturally ate more ice cream, showing only an association or correlation.</code></pre></div>\n<p>So, does eating ice cream or hot weather cause polio?</p>\n<h2 id=\"detecting-and-measuring-correlation\"><a href=\"#detecting-and-measuring-correlation\" aria-label=\"detecting and measuring correlation permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Detecting and Measuring Correlation</h2>\n<p>Correlation is most easily detected through exploratory visualization with a scatter plot.</p>\n<p>The strength or degree of correlation is measured by the coefficient of correlation, R.</p>\n<p>The value of R ranges from -1 to +1.</p>\n<ul>\n<li>\n<p>Positive: as one variable increases, the other increases as well</p>\n</li>\n<li>\n<p>Negative: as one variable increases, the other decreases</p>\n</li>\n<li>\n<p>Once a correlation has been established, the relationship can be mathematically quantified in a formula through regression analysis:</p>\n<ul>\n<li>\n<p>Linear regression: line</p>\n</li>\n<li>\n<p>Non-linear regression: curve</p>\n</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"pearson-moment-coefficient-r\"><a href=\"#pearson-moment-coefficient-r\" aria-label=\"pearson moment coefficient r permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Pearson Moment Coefficient R</h2>\n<p><img src=\"http://prometheuswiki.publish.csiro.au/tiki-download_file.php?fileId=370&#x26;display\" alt=\"R Coefficient\"></p>\n<p>Recall that the value of R is between -1 and +1.</p>\n<p>An absolute value close to 1 is a strong correlation, whereas a value close to 0 indicates little to no correlation.</p>\n<p>Values above 0.6 are generally considered to be useful, while values above 0.9 are indications of strong correlations.</p>\n<h2 id=\"assessing-correlation\"><a href=\"#assessing-correlation\" aria-label=\"assessing correlation permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Assessing Correlation</h2>\n<ol>\n<li>Identify the pairs of values to be tested for correlation</li>\n<li>Create a scatter plot of the data</li>\n<li>Visually inspect the clustering and trending of the data to determine if there is  potential for correlation</li>\n<li>Calculate the Pearson Moment coefficient of correlation, R</li>\n<li>Evaluate R</li>\n</ol>\n<h2 id=\"assumption-of-normality\"><a href=\"#assumption-of-normality\" aria-label=\"assumption of normality permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Assumption of Normality</h2>\n<p>The Pearson Moment coefficient of correlation (R) assumes that the data is normally distributed.</p>\n<p>When data is not normally distributed or when the presence of outliers gives a distorted picture of the association between two random variables, the Spearman’s rank correlation is a non-parametric test that can be used instead of the Pearson’s correlation coefficient.</p>\n<p>The Spearman’s rank correlation (also called Spearman’s rho ρ) is the Pearson’s correlation coefficient on the ranks of the data.</p>\n<h2 id=\"determining-normality\"><a href=\"#determining-normality\" aria-label=\"determining normality permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Determining Normality</h2>\n<p>Data that is normally distributed would exhibit a “bell curve” distribution with most values around the mean and fewer values on each tail.</p>\n<p>Normality can be determined in several ways:</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">* perform the Shapiro-Wilk test\n\n* build a Q-Q plot\n\n* visually inspect histogram</code></pre></div>\n<h2 id=\"pearsons-and-spearmans-correlations\"><a href=\"#pearsons-and-spearmans-correlations\" aria-label=\"pearsons and spearmans correlations permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Pearson’s and Spearman’s Correlations</h2>\n<p>To calculate Spearman’s rho, we need to determine the rank for each of the IQ scores and each of the Rock scores, e.g., the rank of the first IQ score (cell A4) is\n=RANK.AVG(A4,A<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mn>4</mn><mo>:</mo><mi>A</mi></mrow><annotation encoding=\"application/x-tex\">4:A</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">4</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">:</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">A</span></span></span></span>13,1).</p>\n<p>Next calculate both correlation coefficients as follows:\nPearson’s =CORREL(A4:A13,B4:B13) = -0.036\nSpearman’s =CORREL(C4:C13,D4:D13) = -0.115</p>\n<p>Result: there is no significant correlation between IQ and listening to rock music based on the sample.</p>\n<h2 id=\"correlation-in-the-presence-of-outliers\"><a href=\"#correlation-in-the-presence-of-outliers\" aria-label=\"correlation in the presence of outliers permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Correlation in the Presence of Outliers</h2>\n<ul>\n<li>\n<p>Outliers can affect the calculation of correlation, so plot the data in a scatter plot or histogram to determine if there are outliers.</p>\n<ul>\n<li>Calculate the Pearson’s correlation coefficient for the sample with and without the outliers. If there isn’t much difference, then the outliers are not influencing the results. </li>\n<li>Calculate the Spearman’s rank coefficient. If it is close to the Pearson’s correlation coefficient, it is also a good indicator that the outliers are not substantially influencing the results.</li>\n<li>If there are clear differences then you will need to determine how you treat the outliers, i.e., whether to remove them.</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"summary\"><a href=\"#summary\" aria-label=\"summary permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Summary</h2>\n<ul>\n<li>Correlation is an important data analysis tool</li>\n<li>The strength of a correlation is expressed with the coefficient of correlation, R</li>\n<li>Correlations can be positive or negative</li>\n<li>Correlation does not equate to causation</li>\n<li>Use the Pearson Moment correlation if the data does not have outliers and is reasonably normally distributed, otherwise use the Spearman Rank correlation</li>\n</ul>\n<h1 id=\"predictive-analytics\"><a href=\"#predictive-analytics\" aria-label=\"predictive analytics permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Predictive Analytics</h1>\n<p>Predictive analytics is an area of data mining that deals with extracting information from data and using it to predict trends and behavior patterns. Often the unknown event of interest is in the future, but predictive analytics can be applied to any type of unknown whether it be in the past, present or future.</p>\n<p>Another definition:</p>\n<p>Predictive analytics is the practice of extracting information from existing data sets in order to determine patterns and predict future outcomes and trends. Predictive analytics does not tell you what will happen in the future. Predictive analytics is largely focused on forecasting under risk where different outcome scenarios occur at differing probabilities.</p>\n<h2 id=\"forecasting\"><a href=\"#forecasting\" aria-label=\"forecasting permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Forecasting</h2>\n<p>Forecasting of demand, storage growth, resources, network traffic, orders, and so forth is a key responsibility of an information scientist.</p>\n<ul>\n<li>\n<p>There are four general approaches:</p>\n<ul>\n<li>Time-Series Models</li>\n<li>Causal Models</li>\n<li>Qualitative Models</li>\n<li>Monte-Carlo Simulation</li>\n</ul>\n</li>\n<li>\n<p>Qualitative Models</p>\n<ul>\n<li>Single and Wide-Band Delphi</li>\n<li>Expert Judgment</li>\n<li>Bottom-Up Composite</li>\n<li>Stakeholder Survey</li>\n</ul>\n</li>\n<li>\n<p>Time-Series Models</p>\n<ul>\n<li>Moving Average</li>\n<li>Exponential Smoothing</li>\n<li>Trend Projection</li>\n</ul>\n</li>\n<li>\n<p>Causal Models</p>\n<ul>\n<li>Linear Regression</li>\n<li>Multiple Regression</li>\n<li>Non-Linear Regression</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"qualitative-models\"><a href=\"#qualitative-models\" aria-label=\"qualitative models permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Qualitative Models</h2>\n<p>Qualitative models incorporate expert opinions and subjective factors.\nUseful when subjective factors are thought to be important or when accurate quantitative data is difficult to obtain.\nCommon qualitative techniques are</p>\n<ul>\n<li>Delphi (single and wideband)</li>\n<li>Expert Judgment</li>\n<li>Bottom-Up Composite</li>\n<li>Stakeholder Survey</li>\n</ul>\n<h2 id=\"time-series-models\"><a href=\"#time-series-models\" aria-label=\"time series models permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Time-Series Models</h2>\n<p>Time-series models attempt to predict growth based on historical data.\nCommon time-series models are</p>\n<ul>\n<li>Moving average</li>\n<li>Exponential smoothing</li>\n<li>Trend projections</li>\n</ul>\n<h2 id=\"causal-models\"><a href=\"#causal-models\" aria-label=\"causal models permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Causal Models</h2>\n<p>Causal models take other factors into account and are often more accurate.\nThe objective is to build a model with the best statistical relationship between the variable being forecast and the independent variables.\nRegression analysis is the most common technique used in causal modeling.</p>\n<h2 id=\"moving-average\"><a href=\"#moving-average\" aria-label=\"moving average permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Moving Average</h2>\n<p>Moving averages work best when the data does not contain any trend or cyclic patterns.\nThe forecast is the average of the most recent n data values, Yt. </p>\n<p>This method tends to smooth out short-term irregularities in the data series.</p>\n<h2 id=\"weighted-moving-average\"><a href=\"#weighted-moving-average\" aria-label=\"weighted moving average permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Weighted Moving Average</h2>\n<p>Weighted moving averages use weights to put more emphasis on recent periods\nOften used when there is slow growth.</p>\n<p><img src=\"https://image.slidesharecdn.com/smoothingmethod-131117195921-phpapp02/95/smoothing-method-4-638.jpg?cb=1384718430\" alt=\"Weighted Average\"></p>\n<h2 id=\"selecting-weights\"><a href=\"#selecting-weights\" aria-label=\"selecting weights permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Selecting Weights</h2>\n<p>Start with equal weights (standard moving average) and then put progressively more weight on the most recent data if there’s growth.\nExponential smoothing is best if there’s more emphasis on recent data.\nRegression trend models are better when there are growth or cycles.</p>\n<h2 id=\"exponential-smoothing\"><a href=\"#exponential-smoothing\" aria-label=\"exponential smoothing permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Exponential Smoothing</h2>\n<p>The smoothing constant (α) is the percentage by which the forecast takes into account the most recent data point.</p>\n<p>F<em>t+1 = F</em>t + α(Y<em>t-F</em>t)</p>\n<p>Start with a smoothing constant α = 0.3 and then adjust the model.\nBootstrap the model by using the first data point as the forecast for the first time period.</p>\n<h2 id=\"holts-method\"><a href=\"#holts-method\" aria-label=\"holts method permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Holt’s Method</h2>\n<p>Holt’s Method adds a trend component to exponential smoothing to produce a second-order model.</p>\n<p>FwT<em>t+1 = F</em>t+T<em>t\nFwT</em>t+1 = F<em>t+(1-β)T</em>t-1+β(F<em>t-F</em>t-1)</p>\n<p>High values for β makes the model more responsive to recent changes in trend.</p>","fields":{"slug":"/posts/2017-02-28-DS-4100-Day-15/","tagSlugs":["/tag/ds/","/tag/r/","/tag/notes/"]},"frontmatter":{"date":"2017-02-28T00:00:00.000Z","description":"Data Collection, Integration, and Analysis","tags":["DS","R","notes"],"title":"DS 4100 Day 15"}}},"pageContext":{"isCreatedByStatefulCreatePages":false,"slug":"/posts/2017-02-28-DS-4100-Day-15/"}}}