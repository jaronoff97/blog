{"expireTime":9007200815364657000,"key":"transformer-remark-markdown-ast-f7e2d99b8116236d9c198bba3ecfb960-gatsby-remark-katexgatsby-remark-imagesgatsby-remark-responsive-iframegatsby-remark-autolink-headersgatsby-remark-prismjsgatsby-remark-copy-linked-filesgatsby-remark-smartypants-","val":{"type":"root","children":[{"type":"heading","depth":3,"children":[{"type":"link","url":"#ds-4100-weekly-review","title":null,"data":{"hProperties":{"aria-label":"ds 4100 weekly review permalink","class":"anchor"},"hChildren":[{"type":"raw","value":"<svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg>"}]}},{"type":"text","value":"DS 4100 Weekly Review","position":{"start":{"line":2,"column":5,"offset":5},"end":{"line":2,"column":26,"offset":26},"indent":[]}}],"position":{"start":{"line":2,"column":1,"offset":1},"end":{"line":2,"column":26,"offset":26},"indent":[]},"data":{"id":"ds-4100-weekly-review","htmlAttributes":{"id":"ds-4100-weekly-review"},"hProperties":{"id":"ds-4100-weekly-review"}}},{"type":"paragraph","children":[{"type":"text","value":"This weekend I worked on the extra credit assignments and did some more research on my project. I’ll start this post with what I learned when doing research with my project and then walkthrough how my extra credit assignments went.","position":{"start":{"line":4,"column":1,"offset":28},"end":{"line":4,"column":232,"offset":259},"indent":[]}}],"position":{"start":{"line":4,"column":1,"offset":28},"end":{"line":4,"column":232,"offset":259},"indent":[]}},{"type":"heading","depth":2,"children":[{"type":"link","url":"#research-project","title":null,"data":{"hProperties":{"aria-label":"research project permalink","class":"anchor"},"hChildren":[{"type":"raw","value":"<svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg>"}]}},{"type":"text","value":"Research project","position":{"start":{"line":6,"column":4,"offset":264},"end":{"line":6,"column":20,"offset":280},"indent":[]}}],"position":{"start":{"line":6,"column":1,"offset":261},"end":{"line":6,"column":20,"offset":280},"indent":[]},"data":{"id":"research-project","htmlAttributes":{"id":"research-project"},"hProperties":{"id":"research-project"}}},{"type":"paragraph","children":[{"type":"text","value":"So this weekend, I was looking a lot into the publicly available data sets for reddit. I found a HUGE one available on google BigQuery which I’ve never used before. Basically, it’s a place for people to store GINORMOUS data sets and run sql queries on them. The reddit data sets I found are around 1 TB large, and queries take a couple seconds to finish. The next thing I think I’m going to do is make my backend/ frontend project on Heroku, or AWS (still can’t decide which one is better for me). Once i have that going, I’m going to begin constructing the frontend for the project, and simulatenously connect to the GBQ so that I can run some basic queries and get basic information. After that I may or may not throw Facebook’s graphQL in the mix, because I think that should make collaborative filtering a bit easier.","position":{"start":{"line":8,"column":1,"offset":282},"end":{"line":8,"column":822,"offset":1103},"indent":[]}}],"position":{"start":{"line":8,"column":1,"offset":282},"end":{"line":8,"column":822,"offset":1103},"indent":[]}},{"type":"heading","depth":2,"children":[{"type":"link","url":"#extra-credit","title":null,"data":{"hProperties":{"aria-label":"extra credit permalink","class":"anchor"},"hChildren":[{"type":"raw","value":"<svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg>"}]}},{"type":"text","value":"Extra Credit","position":{"start":{"line":10,"column":4,"offset":1108},"end":{"line":10,"column":16,"offset":1120},"indent":[]}}],"position":{"start":{"line":10,"column":1,"offset":1105},"end":{"line":10,"column":16,"offset":1120},"indent":[]},"data":{"id":"extra-credit","htmlAttributes":{"id":"extra-credit"},"hProperties":{"id":"extra-credit"}}},{"type":"paragraph","children":[{"type":"text","value":"The extra credit assignments were pretty pretty cool. The first one involved some XML parsing and writing some functions to aggregate XML data. That one wasn’t too interesting. The second one, however, was WAY cooler. The task was to write a parser for a custom file format. The data you’re given is more than 3,000,000 lines of iMDB data. The format’s, on first glance, have many differences, however, after looking and playing with it for a couple minutes I figured out the difference between a Movie and a TV Show (we only want to get the movies in a new data frame). I realized I had two options once I figured out the formatting: \n\t1) write some code and do a bunch of contains\n\t2) write some regexs","position":{"start":{"line":12,"column":1,"offset":1122},"end":{"line":14,"column":22,"offset":1826},"indent":[1,1]}}],"position":{"start":{"line":12,"column":1,"offset":1122},"end":{"line":14,"column":22,"offset":1826},"indent":[1,1]}},{"type":"paragraph","children":[{"type":"text","value":"I decided to do option 2) because the runtime was going to be infinitely faster. The issue with regex is that, I don’t really know it :P so i spent the last couple of hours tweeking and constructing a couple different regexes to find out the year a movie was released, the name of the movie, and whether or not it was a movie, and whether or not it was a tv show. I’m really happy with the final product, and it’s running pretty quickly. I’ve been running it for a while and it’s still on A, though, that being said it’s gone through millions of rows already (it had to sift through all the TV shows first). ","position":{"start":{"line":16,"column":1,"offset":1828},"end":{"line":16,"column":609,"offset":2436},"indent":[]}}],"position":{"start":{"line":16,"column":1,"offset":1828},"end":{"line":16,"column":609,"offset":2436},"indent":[]}}],"position":{"start":{"line":1,"column":1,"offset":0},"end":{"line":16,"column":609,"offset":2436}}}}