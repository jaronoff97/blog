{"expireTime":9007200815366030000,"key":"transformer-remark-markdown-ast-f2aea990ca1e52db7106b00aa6a566d2-gatsby-remark-katexgatsby-remark-imagesgatsby-remark-responsive-iframegatsby-remark-autolink-headersgatsby-remark-prismjsgatsby-remark-copy-linked-filesgatsby-remark-smartypants-","val":{"type":"root","children":[{"type":"heading","depth":3,"children":[{"type":"link","url":"#ds-4100-data-collection-integration-and-analysis","title":null,"data":{"hProperties":{"aria-label":"ds 4100 data collection integration and analysis permalink","class":"anchor"},"hChildren":[{"type":"raw","value":"<svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg>"}]}},{"type":"text","value":"DS 4100 Data Collection, Integration, and Analysis","position":{"start":{"line":2,"column":5,"offset":5},"end":{"line":2,"column":55,"offset":55},"indent":[]}}],"position":{"start":{"line":2,"column":1,"offset":1},"end":{"line":2,"column":55,"offset":55},"indent":[]},"data":{"id":"ds-4100-data-collection-integration-and-analysis","htmlAttributes":{"id":"ds-4100-data-collection-integration-and-analysis"},"hProperties":{"id":"ds-4100-data-collection-integration-and-analysis"}}},{"type":"paragraph","children":[{"type":"text","value":"The reason some of the previous days are missing is because they were either work days or we didn’t have class. Today we’re talking about scraping. ","position":{"start":{"line":4,"column":1,"offset":57},"end":{"line":4,"column":149,"offset":205},"indent":[]}}],"position":{"start":{"line":4,"column":1,"offset":57},"end":{"line":4,"column":149,"offset":205},"indent":[]}},{"type":"heading","depth":2,"children":[{"type":"link","url":"#scraping","title":null,"data":{"hProperties":{"aria-label":"scraping permalink","class":"anchor"},"hChildren":[{"type":"raw","value":"<svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg>"}]}},{"type":"text","value":"Scraping","position":{"start":{"line":6,"column":4,"offset":210},"end":{"line":6,"column":12,"offset":218},"indent":[]}}],"position":{"start":{"line":6,"column":1,"offset":207},"end":{"line":6,"column":12,"offset":218},"indent":[]},"data":{"id":"scraping","htmlAttributes":{"id":"scraping"},"hProperties":{"id":"scraping"}}},{"type":"paragraph","children":[{"type":"text","value":"Scraping often starts with making GET requests. Take the HTML and search through the HTML for the data.","position":{"start":{"line":8,"column":1,"offset":220},"end":{"line":8,"column":104,"offset":323},"indent":[]}}],"position":{"start":{"line":8,"column":1,"offset":220},"end":{"line":8,"column":104,"offset":323},"indent":[]}},{"type":"paragraph","children":[{"type":"text","value":"Process:","position":{"start":{"line":10,"column":1,"offset":325},"end":{"line":10,"column":9,"offset":333},"indent":[]}}],"position":{"start":{"line":10,"column":1,"offset":325},"end":{"line":10,"column":9,"offset":333},"indent":[]}},{"type":"paragraph","children":[{"type":"text","value":"Get a website -> Scrape it -> Get data","position":{"start":{"line":12,"column":1,"offset":335},"end":{"line":12,"column":39,"offset":373},"indent":[]}}],"position":{"start":{"line":12,"column":1,"offset":335},"end":{"line":12,"column":39,"offset":373},"indent":[]}},{"type":"paragraph","children":[{"type":"text","value":"Be careful of websites that do not allow web scraping. A LOT of data is copyrighted. Regex is very useful when writing a scraper. ","position":{"start":{"line":14,"column":1,"offset":375},"end":{"line":14,"column":131,"offset":505},"indent":[]}}],"position":{"start":{"line":14,"column":1,"offset":375},"end":{"line":14,"column":131,"offset":505},"indent":[]}},{"type":"paragraph","children":[{"type":"text","value":"Now we’re going over how to scrape in R, which is a weird process. I wrote a scraper in python, and I’m just going to translate it into R, it’s going to be weird, but it should work. I think I’m going to use the ","position":{"start":{"line":16,"column":1,"offset":507},"end":{"line":16,"column":213,"offset":719},"indent":[]}},{"type":"strong","children":[{"type":"text","value":"rvest","position":{"start":{"line":16,"column":215,"offset":721},"end":{"line":16,"column":220,"offset":726},"indent":[]}}],"position":{"start":{"line":16,"column":213,"offset":719},"end":{"line":16,"column":222,"offset":728},"indent":[]}},{"type":"text","value":" package, it seeems easy to use and it’s supposed to be inspired by ","position":{"start":{"line":16,"column":222,"offset":728},"end":{"line":16,"column":290,"offset":796},"indent":[]}},{"type":"strong","children":[{"type":"text","value":"BeautifulSoup","position":{"start":{"line":16,"column":292,"offset":798},"end":{"line":16,"column":305,"offset":811},"indent":[]}}],"position":{"start":{"line":16,"column":290,"offset":796},"end":{"line":16,"column":307,"offset":813},"indent":[]}},{"type":"text","value":" which is the package I was using in Python.","position":{"start":{"line":16,"column":307,"offset":813},"end":{"line":16,"column":351,"offset":857},"indent":[]}}],"position":{"start":{"line":16,"column":1,"offset":507},"end":{"line":16,"column":351,"offset":857},"indent":[]}}],"position":{"start":{"line":1,"column":1,"offset":0},"end":{"line":17,"column":1,"offset":858}}}}