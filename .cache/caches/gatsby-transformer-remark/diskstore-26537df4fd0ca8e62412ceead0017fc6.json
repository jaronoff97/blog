{"expireTime":9007200815364657000,"key":"transformer-remark-markdown-ast-0cd94351972c78af6661ed066cb8ce2d-gatsby-remark-katexgatsby-remark-imagesgatsby-remark-responsive-iframegatsby-remark-autolink-headersgatsby-remark-prismjsgatsby-remark-copy-linked-filesgatsby-remark-smartypants-","val":{"type":"root","children":[{"type":"heading","depth":3,"children":[{"type":"link","url":"#ds-4100-weekly-review","title":null,"data":{"hProperties":{"aria-label":"ds 4100 weekly review permalink","class":"anchor"},"hChildren":[{"type":"raw","value":"<svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg>"}]}},{"type":"text","value":"DS 4100 Weekly Review","position":{"start":{"line":2,"column":5,"offset":5},"end":{"line":2,"column":26,"offset":26},"indent":[]}}],"position":{"start":{"line":2,"column":1,"offset":1},"end":{"line":2,"column":26,"offset":26},"indent":[]},"data":{"id":"ds-4100-weekly-review","htmlAttributes":{"id":"ds-4100-weekly-review"},"hProperties":{"id":"ds-4100-weekly-review"}}},{"type":"paragraph","children":[{"type":"text","value":"This week I want to brainstorm more about my project. I really like the idea of doing some reddit scraping. I’ve been looking at a lot of cool reddit data science projects. There have been a couple stand out projects in the past year that have really interested me; there was one about the occurance of swear words in different popular subreddits; another was about linking to news websites in different political subreddits; another was about subreddits that are the most supportive/ kind. That kind of sentiment analysis over such a large data set is really cool. ","position":{"start":{"line":5,"column":1,"offset":29},"end":{"line":5,"column":567,"offset":595},"indent":[]}}],"position":{"start":{"line":5,"column":1,"offset":29},"end":{"line":5,"column":567,"offset":595},"indent":[]}},{"type":"paragraph","children":[{"type":"text","value":"While it’s cool that these people generated a top and bottom ten list for their criteria, I want something that’s a bit more dynamic, so that the layman could use it. Here’s how the website would work: a user types in a list of words (one word is also valid), a subreddit, and a time frame. The website then makes a call to the backend with the data. The backend then looks if the subreddit’s data has already been added to the database, if it has been added the process is kicked off, if it hasn’t, the api is hit and the data is added to the database. I already have the skeleton for adding data to the database, so that part shouldn’t be too hard. ","position":{"start":{"line":7,"column":1,"offset":597},"end":{"line":7,"column":652,"offset":1248},"indent":[]}}],"position":{"start":{"line":7,"column":1,"offset":597},"end":{"line":7,"column":652,"offset":1248},"indent":[]}},{"type":"paragraph","children":[{"type":"text","value":"The process to be kicked off is the following: get all the times in the database the word has been used. From that point on we can return a bunch of different statistics about the word’s usage: the amount of times it’s been used, the average amount of points for the word, the max and the min, etc. I can also display a graph of the amount of times it’s been used per post per day in the timeframe. ","position":{"start":{"line":9,"column":1,"offset":1250},"end":{"line":9,"column":400,"offset":1649},"indent":[]}}],"position":{"start":{"line":9,"column":1,"offset":1250},"end":{"line":9,"column":400,"offset":1649},"indent":[]}},{"type":"paragraph","children":[{"type":"text","value":"I would also love to see how different people use the service, and collect some analytics on how it’s being used. I would love to use the analytics for more information about how to make the service better.","position":{"start":{"line":11,"column":1,"offset":1651},"end":{"line":11,"column":207,"offset":1857},"indent":[]}}],"position":{"start":{"line":11,"column":1,"offset":1651},"end":{"line":11,"column":207,"offset":1857},"indent":[]}}],"position":{"start":{"line":1,"column":1,"offset":0},"end":{"line":11,"column":207,"offset":1857}}}}