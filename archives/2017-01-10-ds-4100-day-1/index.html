<!doctype html><html class="not-ready text-sm lg:text-base" style=--bg:#faf6f1 lang=en-us><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><title>DS 4100 Day 1 - Blog</title><meta name=theme-color><meta name=description content="DS 4100 Data Collection, Integration, and Analysis Course Website
Just like my CS 3500 posts, this series is for my data science class notes. This class is what most of my R tutorial posts have been for (I&rsquo;m going to continue those until I finish the book). Here are the units:
Unit 1 - Essentials Concepts of Data Science Unit 2 - Programming in R for Data Science Unit 3 - Data Collection & Integration Unit 4 - Data Storage Unit 5 - Data Analytics Unit 6 - Python Programming for Data Science Unit 7 - Data Quality & Governance So it seems like we start with R, and eventually get to Python."><meta name=author content><link rel="preload stylesheet" as=style href=https://jaronoff97.github.io/main.min.css><link rel=preload as=image href=https://jaronoff97.github.io/theme.png><link rel=preload as=image href="https://www.gravatar.com/avatar/1ffba55621ec04ac018b48dbb1ea6d69?s=160&d=identicon"><link rel=preload as=image href=https://jaronoff97.github.io/twitter.svg><link rel=preload as=image href=https://jaronoff97.github.io/github.svg><link rel=preload as=image href=https://jaronoff97.github.io/instagram.svg><link rel=preload as=image href=https://jaronoff97.github.io/rss.svg><link rel=preload as=image href=https://jaronoff97.github.io/linkedin.svg><link rel=icon href=https://jaronoff97.github.io/favicon.ico><link rel=apple-touch-icon href=https://jaronoff97.github.io/apple-touch-icon.png><meta name=generator content="Hugo 0.102.3"><meta property="og:title" content="DS 4100 Day 1"><meta property="og:description" content="Data Collection, Integration, and Analysis"><meta property="og:type" content="article"><meta property="og:url" content="https://jaronoff97.github.io/archives/2017-01-10-ds-4100-day-1/"><meta property="article:section" content="archives"><meta property="article:published_time" content="2017-01-10T00:00:00+00:00"><meta property="article:modified_time" content="2017-01-10T00:00:00+00:00"><meta itemprop=name content="DS 4100 Day 1"><meta itemprop=description content="Data Collection, Integration, and Analysis"><meta itemprop=datePublished content="2017-01-10T00:00:00+00:00"><meta itemprop=dateModified content="2017-01-10T00:00:00+00:00"><meta itemprop=wordCount content="973"><meta itemprop=keywords content="DS,R,notes,"><meta name=twitter:card content="summary"><meta name=twitter:title content="DS 4100 Day 1"><meta name=twitter:description content="Data Collection, Integration, and Analysis"></head><body class="text-black duration-200 ease-out dark:text-white"><header class="mx-auto flex h-[5rem] max-w-3xl px-8 lg:justify-center"><div class="relative z-50 mr-auto flex items-center"><a class="-translate-x-[1px] -translate-y-0.5 text-3xl font-bold" href=https://jaronoff97.github.io>Blog</a>
<a class="btn-dark ml-6 h-6 w-6 shrink-0 cursor-pointer [background:url(./theme.svg)_left_center/cover_no-repeat] dark:invert dark:[background-position:right]"></a></div><a class="btn-menu relative z-50 -mr-8 flex h-[5rem] w-[5rem] shrink-0 cursor-pointer flex-col items-center justify-center gap-2.5 lg:hidden"></a>
<script>const htmlClass=document.documentElement.classList;setTimeout(()=>{htmlClass.remove("not-ready")},10);const btnMenu=document.querySelector(".btn-menu");btnMenu.addEventListener("click",()=>{htmlClass.toggle("open")});const metaTheme=document.querySelector('meta[name="theme-color"]'),lightBg=`"#faf6f1"`.replace(/"/g,""),setDark=e=>{metaTheme.setAttribute("content",e?"#000":lightBg),htmlClass[e?"add":"remove"]("dark"),localStorage.setItem("dark",e)},darkScheme=window.matchMedia("(prefers-color-scheme: dark)"),darkVal=localStorage.getItem("dark");setDark(darkVal?darkVal==="true":darkScheme.matches),darkScheme.addEventListener("change",e=>{setDark(e.matches)});const btnDark=document.querySelector(".btn-dark");btnDark.addEventListener("click",()=>{setDark(localStorage.getItem("dark")!=="true")})</script><div class="nav-wrapper fixed inset-x-0 top-full z-40 flex h-full select-none flex-col justify-center pb-16 duration-200 dark:bg-black lg:static lg:h-auto lg:flex-row lg:!bg-transparent lg:pb-0 lg:transition-none"><nav class="lg:ml-12 lg:flex lg:flex-row lg:items-center lg:space-x-6"><a class="block text-center text-2xl leading-[5rem] lg:text-base lg:font-normal" href=/about/>About</a>
<a class="block text-center text-2xl leading-[5rem] lg:text-base lg:font-normal" href=/archives/>Archives</a>
<a class="block text-center text-2xl leading-[5rem] lg:text-base lg:font-normal" href=/resume/>Resume</a></nav><nav class="mt-12 flex justify-center space-x-10 dark:invert lg:mt-0 lg:ml-12 lg:items-center lg:space-x-6"><a class="h-8 w-8 [background:var(--url)_center_center/cover_no-repeat] lg:h-6 lg:w-6" style=--url:url(./twitter.svg) href=https://twitter.com/get_sw1fty target=_blank></a>
<a class="h-8 w-8 [background:var(--url)_center_center/cover_no-repeat] lg:h-6 lg:w-6" style=--url:url(./github.svg) href=https://github.com/jaronoff97 target=_blank></a>
<a class="h-8 w-8 [background:var(--url)_center_center/cover_no-repeat] lg:h-6 lg:w-6" style=--url:url(./instagram.svg) href=https://instagram.com/ehicouldeat target=_blank></a>
<a class="h-8 w-8 [background:var(--url)_center_center/cover_no-repeat] lg:h-6 lg:w-6" style=--url:url(./rss.svg) href=https://jaronoff97.github.io/index.xml target=_blank></a>
<a class="h-8 w-8 [background:var(--url)_center_center/cover_no-repeat] lg:h-6 lg:w-6" style=--url:url(./linkedin.svg) href=https://linkedin.com/jaronoff97 target=_blank></a></nav></div></header><main class="prose prose-neutral relative mx-auto min-h-[calc(100%-10rem)] max-w-3xl px-8 pt-20 pb-32 dark:prose-invert"><article><header class=mb-20><h1 class="!my-0 pb-2.5">DS 4100 Day 1</h1><div class="text-sm opacity-60"><time>Jan 10, 2017</time></div></header><section><h3 id=ds-4100-data-collection-integration-and-analysis>DS 4100 Data Collection, Integration, and Analysis</h3><p><a href=http://ds4100.weebly.com>Course Website</a></p><p>Just like my <a href=http://jaronoff.com/CS-3500-Day-1/>CS 3500</a> posts, this series is for my data science class notes. This class is what most of my R tutorial posts have been for (I&rsquo;m going to continue those until I finish the book). Here are the units:</p><ul><li>Unit 1 - Essentials Concepts of Data Science</li><li>Unit 2 - Programming in R for Data Science</li><li>Unit 3 - Data Collection & Integration</li><li>Unit 4 - Data Storage</li><li>Unit 5 - Data Analytics</li><li>Unit 6 - Python Programming for Data Science</li><li>Unit 7 - Data Quality & Governance</li></ul><p>So it seems like we start with R, and <strong>eventually</strong> get to Python. The first part is all about the concepts. The teacher calls it &ldquo;plumbing&rdquo; the stuff about collection and integration. Getting data from SO many different sources (Files, JSON, XML, Scraping, APIs). Then we go to data storage in SQL and NoSQL. Then we leave &ldquo;plumbing&rdquo; and do data analytics: descriptive analytics and predictive analytics :) :) :) :); data mining, machine learning, etc (REALLY COOL STUFF). Then we do visualization and communicating results leading into building analytics reports. Then a little Python programming and checking the quality of data. It also sounds like this is a job prep kind of class where at the end I&rsquo;ll be job ready for DS.</p><h1 id=module-1>Module 1</h1><p>This module is about the role of data scientists, the value of data, and the course structure</p><p>Data drives decision making in organizations. The product team needs information to satisfy customers. We&rsquo;re not going to be doing machine learning, this is going to be mainly human driven learning (we&rsquo;ll do a little bit AI.) Many people think that a computer generated answer is more true than a human, just because you built a predictive model doesn&rsquo;t mean that it&rsquo;s true. Algorithms may contain bias. Loans in the 1950s often had bias, in the 70&rsquo;s a company began collecting data about bank customers. This company then created the FICO credit score which is a number that predicts the likeliness that someone will pay back a loan. Colleges now use a similar system for accepting students. When you start building models like this, do the biases go away? Initially it looks like they do, but often times they actually don&rsquo;t. There is an ethical component to the work we do, whether you like it or not, biases can be inadvertantly built in to a model. Teacher recommends reading <a href=https://www.amazon.com/Weapons-Math-Destruction-Increases-Inequality/dp/0553418815>Weapons of math destruction</a>, it&rsquo;s about a woman who realized how often her work was being misused and all the times there was inherent bias in her models.</p><h2 id=the-role-of-the-data-scientist>The role of the Data Scientist</h2><p>DS turn data into actionable information. A lot of data science work is to clean up data. 80-90% of data looks like crap. How do you know data types if they aren&rsquo;t there? How can you make inferences such that you have better information. I.E. how do you determine the gender based off of a first name? A possible project later in the semester is to participate in a data challenge <a href=http://kaggle.com>an example of a challenge</a>.</p><h2 id=data-repositories>Data Repositories</h2><p>Data is stored in TONS of ways:</p><ul><li>CSV</li><li>XML</li><li>JSON</li><li>MySQL</li><li>Oracle</li><li>SQL Server</li><li>JavaDB</li><li>CouchDB</li><li>Mongo</li><li>Hadoop</li><li>Redis</li><li>Cassandra</li><li>HTML</li><li>Some bad human formats</li></ul><p>A lot of time is grabbing data from tons of sources and integrating it with others.</p><p>This course goes like this:</p><p>Data collection through scripting &#187;></p><p>Quality Assesment & Cleaning &#187;></p><p>Storage in analysis-appropriate Data Stores &#187;></p><p>Clean data ready to retrieve for analytics & visualization.</p><h2 id=module-2>Module 2</h2><p>Big data:</p><ul><li>Big data is a new term that describes large, complex data sets that need to be stored and processed in different ways</li><li>Larger data sets allow for more detailed analysis</li><li>It&rsquo;s very dependent on the time (in the future what will be considered big data is very different than what big data is now)</li></ul><p>Important facts:</p><ul><li>Volume of data is growing, each day over 2.5 quintillion bytes of data is being generated.</li><li>90% of the world&rsquo;s data has been generated over the past two years</li><li>Data from multiple sources is being integrated into one massive source</li></ul><p>Sources of data:</p><ul><li>There are nearly five billion web pages</li><li>Collected data includes network traffic, site and page visits, page navigation, page searches</li><li>User generated content</li><li>Facebook</li><li>Twitter</li><li>Instagram</li><li>Blogs</li><li>YouTube</li><li>Forums</li><li>Wikis</li><li>etc</li><li>RFID (radio frequency ids)</li><li>Tags for tracking merchandise and shipments, sports performance, automated toll collection</li><li>GPS tracking data generated by mobile devices</li><li>Tracking of movement of equipment, vehicles, and people</li><li>Weather conditions</li><li>Tidal movements</li><li>Transactional data</li><li>Census</li><li>Polls</li><li>Healthcare data</li><li>Education, law and order, economic activity, agriculture, food production</li><li>Radio telescopes, particle physics</li></ul><p><strong>Definition of &ldquo;Big Data&rdquo;</strong>: Big data is the integration of large amounts of multiple types of structured and unstructured data into a single data set that can be analyzed to gain insight and new understanding of an industry, business, the enviroment, medicine, disease control, science, and the human interactinos and expectations.</p><p>Big Data Characteristics:</p><ul><li>Large, distributed aggregations of loosely structured data</li><li>Excess of multiple petabytes and exabytes</li><li>Billions of records about people or transactions</li></ul><p>Information Quality:</p><ul><li>Information/ Data quality is a measurement of the fit of information for particular use</li><li>Poor information quality can cost businesses 10% of revenue</li><li>Bad info can account for $600 billion loss in USA</li></ul><p>The 6 V&rsquo;s of Big Data</p><ul><li>Volume<ul><li>Large quantity</li><li>2.7 zetabytes of data in the universe, expected to double every two years</li></ul></li><li>Variety<ul><li>A lot of data sources</li><li>Not just one type</li></ul></li><li>Velocity<ul><li>How quickly we can process it</li><li>How quickly it emerges</li></ul></li><li>Veracity<ul><li>Truthfullness of data</li><li>Reliability of data</li></ul></li><li>Validity<ul><li>Correct syntax & expected type</li><li>Appropriate for the analysis you&rsquo;re doing</li></ul></li><li>Volatility<ul><li>How long you can store data for before it&rsquo;s obsolete</li></ul></li></ul><p><strong>Self reported data has a lot of veracity concerns</strong></p></section><footer class="mt-12 flex flex-wrap"><a class="mr-1.5 mb-1.5 rounded-lg bg-black/[3%] px-5 py-2 no-underline dark:bg-white/[8%]" href=https://jaronoff97.github.io/tags/ds>DS</a>
<a class="mr-1.5 mb-1.5 rounded-lg bg-black/[3%] px-5 py-2 no-underline dark:bg-white/[8%]" href=https://jaronoff97.github.io/tags/r>R</a>
<a class="mr-1.5 mb-1.5 rounded-lg bg-black/[3%] px-5 py-2 no-underline dark:bg-white/[8%]" href=https://jaronoff97.github.io/tags/notes>notes</a></footer></article></main><footer class="opaco mx-auto flex h-[5rem] max-w-3xl items-center px-8 text-[0.9em] opacity-60"><div class=mr-auto>&copy; 2022
<a class=link href=https://jaronoff97.github.io>Blog</a></div><a class="link mx-6" href=https://gohugo.io/ rel=noopener target=_blank>Powered by Hugo️️</a>️
<a class=link href=https://github.com/nanxiaobei/hugo-paper rel=noopener target=_blank>▷ Paper 6</a></footer></body></html>